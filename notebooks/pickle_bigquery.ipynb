{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# This notebook pickle-izes an unzipped directory of Bigquery data.\n",
    "\n",
    "\n",
    "DIRECTORY = \"data/bigquery\"\n",
    "SMALLER_DIRECTORY = \"data/bigquery_processed\"\n",
    "OUTPUT_PICKLE = \"all_data.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58cd532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(DIRECTORY):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    "filenames = [os.path.join(DIRECTORY, filename) for filename in f]\n",
    "filenames = sorted(filenames)\n",
    "\n",
    "other_irrelevant_columns = [\"Response\", \"UncensoredResponse\", \"MiddleboxASName\", 'PreviousMiddleboxIP', 'PreviousMiddleboxASN', 'PreviousMiddleboxCountry', 'MiddleboxIP', 'MiddleboxASN', 'MiddleboxCountry', 'NextMiddleboxIP', 'NextMiddleboxASN', 'NextMiddleboxCountry']\n",
    "\n",
    "cutting down on dataset size\n",
    "go thru each file and discard columns unneeded for feature extraction\n",
    "\n",
    "dfs = []\n",
    "count = 0\n",
    "for filename in filenames:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    if count % 10 == 0:\n",
    "        path = os.path.join(SMALLER_DIRECTORY, os.path.basename(filename))\n",
    "        pd.concat(dfs).to_csv(path)\n",
    "        dfs = []\n",
    "    print(f\"Reading {filename}...\")\n",
    "    df = pd.read_csv(filename, low_memory=False) # TODO: explicitly specify dtypes to make this run much faster\n",
    "    application_columns = [col for col in list(df.columns) if col.startswith(\"Censys\") or col.startswith(\"Zgrab\") ]\n",
    "    df = df.drop(application_columns + other_irrelevant_columns, 1)\n",
    "    dfs.append(df)\n",
    "\n",
    "# combine all the resultant processed files into one big pickle\n",
    "\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(SMALLER_DIRECTORY):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    "filenames = [os.path.join(SMALLER_DIRECTORY, filename) for filename in f]\n",
    "filenames = sorted(filenames)\n",
    "dfs = []\n",
    "for filename in filenames:\n",
    "    dfs.append(pd.read_csv(filename, low_memory=False))\n",
    "dfs = pd.concat(dfs)\n",
    "dfs.to_pickle(OUTPUT_PICKLE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
